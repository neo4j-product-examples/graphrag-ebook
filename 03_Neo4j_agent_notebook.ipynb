{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neo4j + LLM Conversational Agent Notebook\n",
    "\n",
    "This notebook demonstrates a conversational agent that:\n",
    "- Uses LangChain, OpenAI, and Neo4j to answer questions about company risk factors.\n",
    "- Tracks each conversation session and every message in Neo4j.\n",
    "- Logs which company and risk factor nodes were involved in each answer.\n",
    "- Maintains message order: Each message in a session is linked to the next message via a `:NEXT` relationship, allowing you to traverse the conversation in order.\n",
    "\n",
    "**Data Model:**\n",
    "- `Session` nodes represent a user's chat session.\n",
    "- `Message` nodes represent each question/answer pair.\n",
    "- Relationships:\n",
    "    - `(:Session)-[:HAS_MESSAGE]->(:Message)` links sessions to messages.\n",
    "    - `(:Message)-[:NEXT]->(:Message)` links each message to the next in the session.\n",
    "    - `(:Message)-[:INVOLVES_COMPANY]->(:Company)` and `(:Message)-[:INVOLVES_RISK]->(:RiskFactor)` track which nodes were referenced in the answer.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment and Dependency Setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_neo4j import Neo4jChatMessageHistory, Neo4jGraph\n",
    "from uuid import uuid4\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Make sure your `.env` file contains your Neo4j and OpenAI credentials:\n",
    "\n",
    "```\n",
    "NEO4J_URI=neo4j+s://<your-instance>.databases.neo4j.io\n",
    "NEO4J_USERNAME=your_username\n",
    "NEO4J_PASSWORD=your_password\n",
    "OPENAI_API_KEY=your_openai_key\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_ID = str(uuid4())\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv('NEO4J_URI'),\n",
    "    username=os.getenv('NEO4J_USERNAME'),\n",
    "    password=os.getenv('NEO4J_PASSWORD'),\n",
    ")\n",
    "print(f'Session ID: {SESSION_ID}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Prompt and Tool Definition\n",
    "The agent uses a prompt that restricts answers to only what is in the graph. The tool queries risk factors for a given company.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert on SEC filings and company data. ALWAYS use the provided tools to answer questions. NEVER answer directly. If you don't know, say you don't know.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "last_query_nodes = {}\n",
    "def company_query_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Query Neo4j for risk factors associated with a company.\n",
    "    Returns company name and a list of risk factor names and IDs.\n",
    "    Also saves the involved node IDs for logging.\n",
    "    \"\"\"\n",
    "    cypher = \"\"\"\n",
    "    MATCH (c:Company)-[:FACES_RISK]->(r:RiskFactor)\n",
    "    WHERE toLower(c.name) CONTAINS toLower($query)\n",
    "    RETURN elementId(c) AS company_id, c.name AS company_name, collect({id: elementId(r), text: r.name}) AS risks\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    results = graph.query(cypher, params={\"query\": query})\n",
    "    if results:\n",
    "        company_id = results[0]['company_id']\n",
    "        company_name = results[0]['company_name']\n",
    "        risks = results[0]['risks']\n",
    "        risk_lines = \"\\n\".join([f\"- {r['text']} (id: {r['id']})\" for r in risks])\n",
    "        global last_query_nodes\n",
    "        last_query_nodes = {\n",
    "            \"company_id\": company_id,\n",
    "            \"risk_ids\": [r['id'] for r in risks]\n",
    "        }\n",
    "        return f\"Company: {company_name} (id: {company_id})\\nRisk Factors:\\n{risk_lines}\"\n",
    "    last_query_nodes.clear()\n",
    "    return \"No matching company or risk factors found.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging: Store Session, Message, and Relationships\n",
    "Each message is stored as a node and linked to the session. Messages are chained in order by the `:NEXT` relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_query_nodes_to_neo4j(session_id, question, answer, company_id, risk_ids):\n",
    "    \"\"\"\n",
    "    Log the session, message, and involved nodes to Neo4j.\n",
    "    Also chains messages in order via :NEXT relationship.\n",
    "    \"\"\"\n",
    "    cypher = \"\"\"\n",
    "    MERGE (s:Session {id: $session_id})\n",
    "    WITH s\n",
    "    OPTIONAL MATCH (s)-[:HAS_MESSAGE]->(prev:Message)\n",
    "    WITH s, prev\n",
    "    ORDER BY prev.timestamp DESC\n",
    "    LIMIT 1\n",
    "    CREATE (m:Message {question: $question, answer: $answer, timestamp: datetime()})\n",
    "    MERGE (s)-[:HAS_MESSAGE]->(m)\n",
    "    FOREACH (_ IN CASE WHEN prev IS NOT NULL THEN [1] ELSE [] END |\n",
    "        MERGE (prev)-[:NEXT]->(m)\n",
    "    )\n",
    "    WITH m\n",
    "    MATCH (c) WHERE elementId(c) = $company_id\n",
    "    MERGE (m)-[:INVOLVES_COMPANY]->(c)\n",
    "    WITH m\n",
    "    UNWIND $risk_ids AS rid\n",
    "    MATCH (r) WHERE elementId(r) = rid\n",
    "    MERGE (m)-[:INVOLVES_RISK]->(r)\n",
    "    \"\"\"\n",
    "    graph.query(\n",
    "        cypher,\n",
    "        params={\n",
    "            \"session_id\": session_id,\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"company_id\": company_id,\n",
    "            \"risk_ids\": risk_ids,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent, Tool, and Memory Setup: Detailed Explanation\n",
    "\n",
    "This section configures the conversational agent using LangChain, Neo4j, and OpenAI.  \n",
    "Below is a breakdown of each component, its purpose, and links to official documentation or source code.\n",
    "\n",
    "- **Tool.from_function**  \n",
    "  Registers a custom Python function as a tool the agent can use.  \n",
    "  [Docs: Custom Tools](https://python.langchain.com/docs/modules/agents/tools/custom_tools/)\n",
    "\n",
    "- **tools**  \n",
    "  A list of all tools available to the agent.  \n",
    "  [Docs: Tools for Agents](https://python.langchain.com/docs/modules/agents/tools/)\n",
    "\n",
    "- **hub.pull(\"hwchase17/react-chat\")**  \n",
    "  Loads a high-quality, community prompt template for the ReAct agent from the [LangChain Hub](https://python.langchain.com/docs/hub/).  \n",
    "  [Prompt Example](https://smith.langchain.com/hub/hwchase17/react-chat)\n",
    "\n",
    "- **create_react_agent**  \n",
    "  Creates a ReAct-style agent that can use tools, reason, and answer questions.  \n",
    "  [Docs: ReAct Agent](https://python.langchain.com/docs/modules/agents/agent_types/react/)\n",
    "\n",
    "- **AgentExecutor**  \n",
    "  Wraps the agent and tools into an executable interface.  \n",
    "  [Docs: AgentExecutor](https://python.langchain.com/docs/modules/agents/agent_executor/)\n",
    "\n",
    "- **Neo4jChatMessageHistory**  \n",
    "  Provides persistent, session-based chat memory in Neo4j.  \n",
    "  [Docs: Message History](https://python.langchain.com/docs/modules/memory/message_history/)\n",
    "\n",
    "- **RunnableWithMessageHistory**  \n",
    "  Wraps the agent to provide context-aware responses using message history.  \n",
    "  [Docs: RunnableWithMessageHistory](https://python.langchain.com/docs/modules/memory/message_history/)\n",
    "\n",
    "**Summary Table**\n",
    "\n",
    "| Component                      | Purpose/Role                                         | Docs/Source                                                                                      |\n",
    "|---------------------------------|-----------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| Tool.from_function              | Register function as a tool for the agent           | [Docs](https://python.langchain.com/docs/modules/agents/tools/custom_tools/)                     |\n",
    "| tools                           | List of agent tools                                 | [Docs](https://python.langchain.com/docs/modules/agents/tools/)                                  |\n",
    "| hub.pull                        | Load community prompt template                      | [Docs](https://python.langchain.com/docs/hub/) [Prompt](https://smith.langchain.com/hub/hwchase17/react-chat) |\n",
    "| create_react_agent              | Create a ReAct agent                                | [Docs](https://python.langchain.com/docs/modules/agents/agent_types/react/)                      |\n",
    "| AgentExecutor                   | Run agent and tools                                 | [Docs](https://python.langchain.com/docs/modules/agents/agent_executor/)                         |\n",
    "| Neo4jChatMessageHistory         | Store/retrieve session chat history in Neo4j        | [Docs](https://python.langchain.com/docs/modules/memory/message_history/)                        |\n",
    "| RunnableWithMessageHistory      | Add memory to agent for context-aware responses     | [Docs](https://python.langchain.com/docs/modules/memory/message_history/)                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tool = Tool.from_function(\n",
    "    name=\"Company Info\",\n",
    "    description=\"Query the graph for company risk factors or information. Input is a company name or question.\",\n",
    "    func=company_query_tool,\n",
    ")\n",
    "tools = [company_tool]\n",
    "agent_prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "agent = create_react_agent(llm, tools, agent_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True)\n",
    "\n",
    "def get_memory(session_id):\n",
    "    return Neo4jChatMessageHistory(session_id=session_id, graph=graph)\n",
    "\n",
    "chat_agent = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_memory,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation Handling and Logging\n",
    "\n",
    "This section defines how user questions are sent to the agent, how responses are handled, and how the conversation is logged both in Python and in Neo4j.\n",
    "\n",
    "### `conversation = []`\n",
    "- This is a Python list that stores the full history of the current session in-memory.\n",
    "- Each entry is a dictionary with `\"question\"` and `\"response\"` keys, preserving the order of interaction.\n",
    "- Useful for quickly reviewing the conversation in the notebook, independent of Neo4j.\n",
    "\n",
    "### `def ask_agent(question):`\n",
    "This function is the main interface for interacting with the agent. Here’s what happens step-by-step:\n",
    "\n",
    "1. **Send the Question to the Agent**\n",
    "    - Calls `chat_agent.invoke(...)` with the user’s question and the current session ID.\n",
    "    - The agent uses the full message history for context-aware responses.\n",
    "\n",
    "2. **Capture the Answer**\n",
    "    - Extracts the agent’s answer from the response.\n",
    "\n",
    "3. **Append to Local Conversation**\n",
    "    - Adds a dictionary with the question and response to the `conversation` list.\n",
    "    - This allows you to review the session in the notebook.\n",
    "\n",
    "4. **Log to Neo4j**\n",
    "    - If `last_query_nodes` exists (i.e., the agent used the company tool and found relevant nodes), the function:\n",
    "        - Calls `log_query_nodes_to_neo4j` to:\n",
    "            - Store the session, message, and relationships (company, risk factors) in Neo4j.\n",
    "            - Chain messages in order via the `:NEXT` relationship.\n",
    "\n",
    "5. **Print and Return the Answer**\n",
    "    - Prints the agent’s answer for immediate feedback in the notebook.\n",
    "    - Returns the answer so it can be used in further processing if needed.\n",
    "\n",
    "---\n",
    "\n",
    "**Why is this design useful?**\n",
    "- **Session persistence:** All questions and answers are logged in Neo4j, so the full conversation (and the order of messages) can be reconstructed at any time.\n",
    "- **Node traceability:** Each message is linked to the specific company and risk factor nodes it referenced, enabling downstream graph analysis.\n",
    "- **Notebook review:** The `conversation` list allows you to see the session history without querying Neo4j.\n",
    "- **Reproducibility:** Every run is tracked and can be audited or replayed.\n",
    "\n",
    "**Example usage:**\n",
    "```python\n",
    "ask_agent(\"What are the risk factors for Apple?\")\n",
    "ask_agent(\"What about Microsoft?\")\n",
    "print(conversation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = []\n",
    "def ask_agent(question):\n",
    "    \"\"\"\n",
    "    Ask the agent a question. Logs the message and involved nodes in Neo4j.\n",
    "    Maintains message order within the session.\n",
    "    \"\"\"\n",
    "    response = chat_agent.invoke(\n",
    "        {\"input\": question},\n",
    "        {\"configurable\": {\"session_id\": SESSION_ID}},\n",
    "    )\n",
    "    answer = response[\"output\"]\n",
    "    conversation.append({\"question\": question, \"response\": answer})\n",
    "    if 'last_query_nodes' in globals() and last_query_nodes:\n",
    "        log_query_nodes_to_neo4j(\n",
    "            SESSION_ID,\n",
    "            question,\n",
    "            answer,\n",
    "            last_query_nodes.get(\"company_id\"),\n",
    "            last_query_nodes.get(\"risk_ids\", [])\n",
    "        )\n",
    "    pprint(answer)   \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Usage:**\n",
    "- Use `ask_agent(\"your question\")` to interact with the agent.\n",
    "- Each message is logged and chained in order for the session.\n",
    "- You can query Neo4j to reconstruct the full, ordered conversation for any session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_agent(\"What are the risk factors associated with Apple?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_agent(\"What are the risk factors associated with microsoft?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_agent(\"What are the risk factors are shared by Microsoft and Apple?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Conversation Messages in Neo4j\n",
    "\n",
    "With every message logged in Neo4j (and chained by session), you can perform rich analyses, such as:\n",
    "\n",
    "- **Conversation statistics:** How many messages per session? What is the average/median message length?\n",
    "- **Most discussed companies:** Which companies are most frequently referenced?\n",
    "- **Risk factor trends:** Which risk factors are most often discussed?\n",
    "- **Session timelines:** How does conversation flow over time?\n",
    "- **Message chains:** How are messages ordered and connected?\n",
    "\n",
    "Below are some example analyses and queries you can use.\n",
    "\n",
    "The following code cells use the Neo4j Python driver (via the LangChain `Neo4jGraph` object `graph`) to run Cypher queries and analyze the conversation/message data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of messages in each session\n",
    "cypher = \"\"\"\n",
    "MATCH (s:Session)-[:HAS_MESSAGE]->(m:Message)\n",
    "RETURN s.id AS session_id, count(m) AS message_count\n",
    "ORDER BY message_count DESC\n",
    "\"\"\"\n",
    "results = graph.query(cypher)\n",
    "for row in results:\n",
    "    print(f\"Session {row['session_id']} has {row['message_count']} messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most mentioned companies across all messages\n",
    "cypher = \"\"\"\n",
    "MATCH (m:Message)-[:INVOLVES_COMPANY]->(c:Company)\n",
    "RETURN c.name AS company, count(m) AS mentions\n",
    "ORDER BY mentions DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "results = graph.query(cypher)\n",
    "print(\"Top 10 most mentioned companies:\")\n",
    "for row in results:\n",
    "    print(f\"{row['company']}: {row['mentions']} mentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most mentioned risk factors\n",
    "cypher = \"\"\"\n",
    "MATCH (m:Message)-[:INVOLVES_RISK]->(r:RiskFactor)\n",
    "RETURN r.name AS risk_factor, count(m) AS mentions\n",
    "ORDER BY mentions DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "results = graph.query(cypher)\n",
    "print(\"Top 10 most mentioned risk factors:\")\n",
    "for row in results:\n",
    "    print(f\"{row['risk_factor']}: {row['mentions']} mentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
